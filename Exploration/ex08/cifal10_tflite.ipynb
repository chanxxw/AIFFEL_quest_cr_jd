{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 데이터셋 로드 및 전처리\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # 정규화\n",
    "\n",
    "# 라벨을 원-핫 인코딩\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-10 15:18:21,983] A new study created in memory with name: no-name-47d28fbf-5ccc-49e7-b959-b5850b85a0eb\n",
      "c:\\Users\\envym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float8_e3m4'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-10 15:21:10,041] Trial 0 finished with value: 0.6190999746322632 and parameters: {'learning_rate': 0.003746508630400722, 'num_units': 96}. Best is trial 0 with value: 0.6190999746322632.\n",
      "[I 2024-12-10 15:21:42,752] Trial 1 finished with value: 0.49540001153945923 and parameters: {'learning_rate': 0.009009532019570289, 'num_units': 32}. Best is trial 0 with value: 0.6190999746322632.\n",
      "[I 2024-12-10 15:24:43,565] Trial 2 finished with value: 0.5637999773025513 and parameters: {'learning_rate': 0.00010267950148422044, 'num_units': 96}. Best is trial 0 with value: 0.6190999746322632.\n",
      "[I 2024-12-10 15:26:15,966] Trial 3 finished with value: 0.4925999939441681 and parameters: {'learning_rate': 0.0054753147627106735, 'num_units': 64}. Best is trial 0 with value: 0.6190999746322632.\n",
      "[I 2024-12-10 15:30:09,543] Trial 4 finished with value: 0.6299999952316284 and parameters: {'learning_rate': 0.000390654890583853, 'num_units': 128}. Best is trial 4 with value: 0.6299999952316284.\n",
      "[I 2024-12-10 15:30:44,991] Trial 5 finished with value: 0.5759000182151794 and parameters: {'learning_rate': 0.0003938803209351223, 'num_units': 32}. Best is trial 4 with value: 0.6299999952316284.\n",
      "[I 2024-12-10 15:32:11,532] Trial 6 finished with value: 0.6486999988555908 and parameters: {'learning_rate': 0.0009403547801367684, 'num_units': 64}. Best is trial 6 with value: 0.6486999988555908.\n",
      "[I 2024-12-10 15:34:47,027] Trial 7 finished with value: 0.5418999791145325 and parameters: {'learning_rate': 0.006179602093356801, 'num_units': 96}. Best is trial 6 with value: 0.6486999988555908.\n",
      "[I 2024-12-10 15:39:06,028] Trial 8 finished with value: 0.6118000149726868 and parameters: {'learning_rate': 0.0031538668012771748, 'num_units': 128}. Best is trial 6 with value: 0.6486999988555908.\n",
      "[I 2024-12-10 15:41:49,637] Trial 9 finished with value: 0.6258999705314636 and parameters: {'learning_rate': 0.002563283109049287, 'num_units': 96}. Best is trial 6 with value: 0.6486999988555908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.0009403547801367684, 'num_units': 64}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 정의\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    num_units = trial.suggest_int(\"num_units\", 32, 128, step=32)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(num_units, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_units, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=64, verbose=0)\n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.3257 - loss: 1.8326\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.5369 - loss: 1.2989\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.5892 - loss: 1.1727\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.6150 - loss: 1.0971\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.6351 - loss: 1.0419\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.6555 - loss: 0.9900\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.6675 - loss: 0.9510\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.6802 - loss: 0.9196\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.6920 - loss: 0.8827\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.7028 - loss: 0.8560\n",
      "INFO:tensorflow:Assets written to: saved_model/1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'saved_model/1'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor_66')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1851369128976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1851369137040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1851369138576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1851369129744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1851369131664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1851369142608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "# 최적화된 파라미터 사용\n",
    "best_params = study.best_params\n",
    "final_model = models.Sequential([\n",
    "    layers.Conv2D(best_params[\"num_units\"], (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(best_params[\"num_units\"], activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "final_model.compile(optimizer=Adam(learning_rate=best_params[\"learning_rate\"]),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "final_model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "# 모델 저장\n",
    "final_model.export(\"saved_model/1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {'predictions': [[4.74354283e-06, 2.28325662e-05, 0.000140078919, 3.36624112e-07, 9.56019067e-05, 8.58904059e-09, 0.999700427, 1.68558714e-07, 3.39692585e-09, 3.58887191e-05]]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR-10 이미지 샘플 (32x32x3 크기의 더미 데이터 생성)\n",
    "image = np.random.rand(32, 32, 3).tolist()\n",
    "\n",
    "# REST API 요청\n",
    "url = \"http://localhost:8501/v1/models/cifar10_model:predict\"\n",
    "data = {\"instances\": [image]}\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Predictions:\", response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {'predictions': [[8.44800525e-05, 2.74479044e-05, 0.0160447545, 0.215927765, 0.0262216274, 0.192304417, 0.53503114, 0.014258706, 2.84754551e-05, 7.11921311e-05]]}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# 데이터 로드\n",
    "(x_train, _), _ = cifar10.load_data()\n",
    "\n",
    "# 첫 번째 샘플을 준비\n",
    "data = x_train[:1].astype(\"float32\") / 255.0  # 정규화\n",
    "\n",
    "# REST API 요청\n",
    "response = requests.post(url, json={\"instances\": data.tolist()})\n",
    "print(\"Predictions:\", response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {'predictions': [[1.46709272e-05, 0.00100184383, 6.02009568e-05, 1.03881557e-05, 0.000546160154, 4.389384e-07, 0.998273134, 3.08143062e-05, 4.04766958e-08, 6.21754662e-05]]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# [32x32x3] 크기의 샘플 데이터 생성\n",
    "data = np.random.rand(1, 32, 32, 3).tolist()\n",
    "\n",
    "# REST API 요청\n",
    "url = \"http://localhost:8501/v1/models/cifar10_model:predict\"\n",
    "response = requests.post(url, json={\"instances\": data})\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Predictions:\", response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite 모델이 'model.tflite'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# SavedModel 경로\n",
    "saved_model_dir = \"saved_model/1\"\n",
    "\n",
    "# TFLite 변환기\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# TFLite 모델 저장\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TFLite 모델이 'model.tflite'로 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
