{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">960,000</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_12        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">960,000</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ not_equal_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935,000</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │    \u001b[38;5;34m960,000\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_12        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │    \u001b[38;5;34m960,000\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m), │     \u001b[38;5;34m98,816\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ not_equal_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m), │     \u001b[38;5;34m98,816\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15000\u001b[0m) │  \u001b[38;5;34m1,935,000\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,632</span> (15.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,052,632\u001b[0m (15.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,632</span> (15.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,052,632\u001b[0m (15.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\envym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_102', 'keras_tensor_108']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 100ms/step - accuracy: 0.3027 - loss: 8.0789 - val_accuracy: 0.3293 - val_loss: 7.4661\n",
      "Epoch 2/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.3274 - loss: 7.1378 - val_accuracy: 0.3304 - val_loss: 7.3885\n",
      "Epoch 3/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.3344 - loss: 6.8570 - val_accuracy: 0.3316 - val_loss: 7.3582\n",
      "Epoch 4/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.3374 - loss: 6.6401 - val_accuracy: 0.3336 - val_loss: 7.3534\n",
      "Epoch 5/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 99ms/step - accuracy: 0.3394 - loss: 6.4373 - val_accuracy: 0.3350 - val_loss: 7.3663\n",
      "Epoch 6/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 97ms/step - accuracy: 0.3521 - loss: 6.1971 - val_accuracy: 0.3358 - val_loss: 7.3759\n",
      "Epoch 7/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 96ms/step - accuracy: 0.3567 - loss: 5.9729 - val_accuracy: 0.3367 - val_loss: 7.4005\n",
      "Epoch 8/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 96ms/step - accuracy: 0.3628 - loss: 5.7309 - val_accuracy: 0.3411 - val_loss: 7.4096\n",
      "Epoch 9/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.3738 - loss: 5.4900 - val_accuracy: 0.3409 - val_loss: 7.4327\n",
      "Epoch 10/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.3830 - loss: 5.2599 - val_accuracy: 0.3407 - val_loss: 7.5000\n",
      "Epoch 11/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.3944 - loss: 5.0343 - val_accuracy: 0.3421 - val_loss: 7.5302\n",
      "Epoch 12/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.4030 - loss: 4.8087 - val_accuracy: 0.3398 - val_loss: 7.5915\n",
      "Epoch 13/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.4159 - loss: 4.5871 - val_accuracy: 0.3413 - val_loss: 7.6607\n",
      "Epoch 14/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.4350 - loss: 4.3551 - val_accuracy: 0.3420 - val_loss: 7.7375\n",
      "Epoch 15/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.4527 - loss: 4.1519 - val_accuracy: 0.3380 - val_loss: 7.8344\n",
      "Epoch 16/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.4737 - loss: 3.9566 - val_accuracy: 0.3399 - val_loss: 7.9133\n",
      "Epoch 17/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.4978 - loss: 3.7359 - val_accuracy: 0.3387 - val_loss: 8.0152\n",
      "Epoch 18/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.5214 - loss: 3.5475 - val_accuracy: 0.3384 - val_loss: 8.1281\n",
      "Epoch 19/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 99ms/step - accuracy: 0.5407 - loss: 3.3521 - val_accuracy: 0.3388 - val_loss: 8.2232\n",
      "Epoch 20/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 103ms/step - accuracy: 0.5638 - loss: 3.1648 - val_accuracy: 0.3370 - val_loss: 8.3529\n",
      "Epoch 21/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.5843 - loss: 2.9834 - val_accuracy: 0.3371 - val_loss: 8.4685\n",
      "Epoch 22/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.6053 - loss: 2.8230 - val_accuracy: 0.3372 - val_loss: 8.5949\n",
      "Epoch 23/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.6251 - loss: 2.6600 - val_accuracy: 0.3356 - val_loss: 8.7075\n",
      "Epoch 24/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 100ms/step - accuracy: 0.6484 - loss: 2.4982 - val_accuracy: 0.3314 - val_loss: 8.8295\n",
      "Epoch 25/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.6682 - loss: 2.3603 - val_accuracy: 0.3356 - val_loss: 8.9473\n",
      "Epoch 26/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.6891 - loss: 2.2165 - val_accuracy: 0.3293 - val_loss: 9.0760\n",
      "Epoch 27/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.7075 - loss: 2.0783 - val_accuracy: 0.3349 - val_loss: 9.1953\n",
      "Epoch 28/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.7277 - loss: 1.9456 - val_accuracy: 0.3337 - val_loss: 9.3076\n",
      "Epoch 29/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 99ms/step - accuracy: 0.7461 - loss: 1.8185 - val_accuracy: 0.3325 - val_loss: 9.4325\n",
      "Epoch 30/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.7592 - loss: 1.7290 - val_accuracy: 0.3326 - val_loss: 9.5625\n",
      "Epoch 31/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.7785 - loss: 1.6055 - val_accuracy: 0.3300 - val_loss: 9.7031\n",
      "Epoch 32/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.7934 - loss: 1.5054 - val_accuracy: 0.3290 - val_loss: 9.8127\n",
      "Epoch 33/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 97ms/step - accuracy: 0.8068 - loss: 1.4104 - val_accuracy: 0.3274 - val_loss: 9.9151\n",
      "Epoch 34/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.8198 - loss: 1.3194 - val_accuracy: 0.3271 - val_loss: 10.0318\n",
      "Epoch 35/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 99ms/step - accuracy: 0.8347 - loss: 1.2363 - val_accuracy: 0.3277 - val_loss: 10.1613\n",
      "Epoch 36/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.8493 - loss: 1.1408 - val_accuracy: 0.3256 - val_loss: 10.2900\n",
      "Epoch 37/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 99ms/step - accuracy: 0.8587 - loss: 1.0706 - val_accuracy: 0.3270 - val_loss: 10.3843\n",
      "Epoch 38/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.8676 - loss: 1.0049 - val_accuracy: 0.3262 - val_loss: 10.5186\n",
      "Epoch 39/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.8790 - loss: 0.9284 - val_accuracy: 0.3248 - val_loss: 10.6248\n",
      "Epoch 40/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.8873 - loss: 0.8784 - val_accuracy: 0.3258 - val_loss: 10.7166\n",
      "Epoch 41/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.8991 - loss: 0.8031 - val_accuracy: 0.3257 - val_loss: 10.8285\n",
      "Epoch 42/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 100ms/step - accuracy: 0.9069 - loss: 0.7509 - val_accuracy: 0.3255 - val_loss: 10.9618\n",
      "Epoch 43/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 99ms/step - accuracy: 0.9142 - loss: 0.7016 - val_accuracy: 0.3231 - val_loss: 11.0727\n",
      "Epoch 44/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.9224 - loss: 0.6450 - val_accuracy: 0.3242 - val_loss: 11.1597\n",
      "Epoch 45/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.9280 - loss: 0.6044 - val_accuracy: 0.3229 - val_loss: 11.2821\n",
      "Epoch 46/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 98ms/step - accuracy: 0.9353 - loss: 0.5618 - val_accuracy: 0.3231 - val_loss: 11.3772\n",
      "Epoch 47/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 99ms/step - accuracy: 0.9412 - loss: 0.5203 - val_accuracy: 0.3209 - val_loss: 11.4961\n",
      "Epoch 48/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 99ms/step - accuracy: 0.9454 - loss: 0.4900 - val_accuracy: 0.3213 - val_loss: 11.5833\n",
      "Epoch 49/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 99ms/step - accuracy: 0.9489 - loss: 0.4548 - val_accuracy: 0.3242 - val_loss: 11.6867\n",
      "Epoch 50/50\n",
      "\u001b[1m492/492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 100ms/step - accuracy: 0.9562 - loss: 0.4117 - val_accuracy: 0.3211 - val_loss: 11.7959\n",
      "모델과 토크나이저 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# CSV 파일 경로 (로컬에서 사용하는 경로로 수정)\n",
    "csv_file_path = './news_summary_more.csv'  # CSV 파일 경로를 로컬에 맞게 수정하세요.\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# 'text'와 'headlines' 컬럼만 사용\n",
    "text_data = df['text'].astype(str).values  # 'text' 컬럼\n",
    "summary_data = df['headlines'].astype(str).values  # 'headlines' 컬럼\n",
    "\n",
    "# 데이터셋 샘플링 (데이터 크기를 줄여 Colab 리소스 절약)\n",
    "sample_size = int(len(text_data) * 0.1)  # 데이터의 10%만 샘플링\n",
    "text_data = text_data[:sample_size]\n",
    "summary_data = summary_data[:sample_size]\n",
    "\n",
    "# 데이터셋 분리 (80% train, 20% validation)\n",
    "text_train, text_val, summary_train, summary_val = train_test_split(\n",
    "    text_data, summary_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 토크나이저 생성 및 훈련\n",
    "MAX_TEXT_LEN = 50  # 줄여서 리소스 절약\n",
    "MAX_SUMMARY_LEN = 15  # 줄여서 리소스 절약\n",
    "VOCAB_SIZE = 15000  # 어휘 크기 증가 (기존 10000에서 15000으로)\n",
    "\n",
    "# 텍스트 토크나이저\n",
    "text_tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<UNK>')  # OOV 토큰을 추가하여 범위 외의 단어 처리\n",
    "text_tokenizer.fit_on_texts(text_train)\n",
    "\n",
    "# 요약 토크나이저\n",
    "summary_tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<UNK>')\n",
    "summary_tokenizer.fit_on_texts(summary_train)\n",
    "\n",
    "# 토큰화 및 시퀀스 변환\n",
    "text_train_seq = text_tokenizer.texts_to_sequences(text_train)\n",
    "text_val_seq = text_tokenizer.texts_to_sequences(text_val)\n",
    "\n",
    "# 인덱스를 VOCAB_SIZE 이하로 필터링\n",
    "text_train_seq = [[token if token < VOCAB_SIZE else text_tokenizer.word_index['<UNK>'] for token in seq] for seq in text_train_seq]\n",
    "text_val_seq = [[token if token < VOCAB_SIZE else text_tokenizer.word_index['<UNK>'] for token in seq] for seq in text_val_seq]\n",
    "\n",
    "# 시퀀스 패딩\n",
    "text_train_seq = pad_sequences(text_train_seq, maxlen=MAX_TEXT_LEN, padding='post')\n",
    "text_val_seq = pad_sequences(text_val_seq, maxlen=MAX_TEXT_LEN, padding='post')\n",
    "\n",
    "summary_train_seq = summary_tokenizer.texts_to_sequences(summary_train)\n",
    "summary_val_seq = summary_tokenizer.texts_to_sequences(summary_val)\n",
    "\n",
    "# 인덱스를 VOCAB_SIZE 이하로 필터링\n",
    "summary_train_seq = [[token if token < VOCAB_SIZE else summary_tokenizer.word_index['<UNK>'] for token in seq] for seq in summary_train_seq]\n",
    "summary_val_seq = [[token if token < VOCAB_SIZE else summary_tokenizer.word_index['<UNK>'] for token in seq] for seq in summary_val_seq]\n",
    "\n",
    "# 시퀀스 패딩\n",
    "summary_train_seq = pad_sequences(summary_train_seq, maxlen=MAX_SUMMARY_LEN, padding='post')\n",
    "summary_val_seq = pad_sequences(summary_val_seq, maxlen=MAX_SUMMARY_LEN, padding='post')\n",
    "\n",
    "# 요약 시퀀스에서 시작 토큰 및 종료 토큰 추가\n",
    "START_TOKEN = '<start>'\n",
    "END_TOKEN = '<end>'\n",
    "\n",
    "# 시작 및 종료 토큰 인덱스 추가\n",
    "start_token_idx = len(summary_tokenizer.word_index) + 1\n",
    "end_token_idx = len(summary_tokenizer.word_index) + 2\n",
    "\n",
    "summary_tokenizer.word_index[START_TOKEN] = start_token_idx\n",
    "summary_tokenizer.word_index[END_TOKEN] = end_token_idx\n",
    "summary_tokenizer.index_word[start_token_idx] = START_TOKEN\n",
    "summary_tokenizer.index_word[end_token_idx] = END_TOKEN\n",
    "\n",
    "# 디코더 입력 데이터 및 타겟 데이터 생성\n",
    "decoder_input_train = np.zeros((len(summary_train), MAX_SUMMARY_LEN))\n",
    "decoder_target_train = np.zeros((len(summary_train), MAX_SUMMARY_LEN))\n",
    "\n",
    "for i, seq in enumerate(summary_train_seq):\n",
    "    decoder_input_train[i, 0] = start_token_idx\n",
    "    decoder_input_train[i, 1:] = seq[:-1]  # Shift to create input\n",
    "    decoder_target_train[i, :] = seq\n",
    "\n",
    "# 검증 데이터에 대해서도 디코더 입력과 타겟 데이터 생성\n",
    "decoder_input_val = np.zeros((len(summary_val), MAX_SUMMARY_LEN))\n",
    "decoder_target_val = np.zeros((len(summary_val), MAX_SUMMARY_LEN))\n",
    "\n",
    "for i, seq in enumerate(summary_val_seq):\n",
    "    decoder_input_val[i, 0] = start_token_idx\n",
    "    decoder_input_val[i, 1:] = seq[:-1]\n",
    "    decoder_target_val[i, :] = seq\n",
    "\n",
    "# 모델 정의\n",
    "EMBEDDING_DIM = 64  # 줄여서 리소스 절약\n",
    "HIDDEN_UNITS = 128  # 줄여서 리소스 절약\n",
    "\n",
    "# 인코더 정의\n",
    "encoder_inputs = Input(shape=(MAX_TEXT_LEN,))\n",
    "encoder_embedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(HIDDEN_UNITS, return_state=True, return_sequences=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "# 디코더 정의\n",
    "decoder_inputs = Input(shape=(MAX_SUMMARY_LEN,))\n",
    "decoder_embedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
    "decoder_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(\n",
    "    [text_train_seq, decoder_input_train], \n",
    "    np.expand_dims(decoder_target_train, -1), \n",
    "    epochs=50,  \n",
    "    batch_size=16,  # 배치 크기를 줄여서 리소스 절약\n",
    "    validation_data=([text_val_seq, decoder_input_val], np.expand_dims(decoder_target_val, -1))\n",
    ")\n",
    "\n",
    "# 모델 및 토크나이저 저장\n",
    "model.save(\"news_summary_model_v2.keras\")\n",
    "with open('text_tokenizer_v2.pkl', 'wb') as f:\n",
    "    pickle.dump(text_tokenizer, f)\n",
    "with open('summary_tokenizer_v2.pkl', 'wb') as f:\n",
    "    pickle.dump(summary_tokenizer, f)\n",
    "\n",
    "print(\"모델과 토크나이저 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\envym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['input_layer_6', 'input_layer_7']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Summary: rbi allows 'tokenisation' for data troops over over video threat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 저장된 모델 및 토크나이저 로드\n",
    "model = load_model(\"news_summary_model_v2.keras\")\n",
    "\n",
    "with open('text_tokenizer_v2.pkl', 'rb') as f:\n",
    "    text_tokenizer = pickle.load(f)\n",
    "\n",
    "with open('summary_tokenizer_v2.pkl', 'rb') as f:\n",
    "    summary_tokenizer = pickle.load(f)\n",
    "\n",
    "# 테스트할 예시 텍스트\n",
    "example_text = \"Apple has announced the release of its new iPhone 15, which features an upgraded camera system, faster processor, and a new design with titanium edges. The phone will be available for pre-order starting next week, with shipping expected by the end of the month.\"\n",
    "\n",
    "\n",
    "# 입력 텍스트를 시퀀스로 변환하고 패딩 적용\n",
    "MAX_TEXT_LEN = 50  # 학습 시 사용했던 MAX_TEXT_LEN과 동일해야 함\n",
    "input_sequence = text_tokenizer.texts_to_sequences([example_text])\n",
    "input_sequence = pad_sequences(input_sequence, maxlen=MAX_TEXT_LEN, padding='post')\n",
    "\n",
    "# 디코더 입력 시퀀스 초기화 (START_TOKEN으로 시작)\n",
    "MAX_SUMMARY_LEN = 15  # 학습 시 사용했던 MAX_SUMMARY_LEN과 동일해야 함\n",
    "start_token_idx = summary_tokenizer.word_index['<start>']\n",
    "decoder_input_seq = np.zeros((1, MAX_SUMMARY_LEN))\n",
    "decoder_input_seq[0, 0] = start_token_idx\n",
    "\n",
    "# 요약 생성 (단어 단위로 반복 예측)\n",
    "predicted_summary = \"\"\n",
    "for i in range(1, MAX_SUMMARY_LEN):\n",
    "    # 예측 수행\n",
    "    predictions = model.predict([input_sequence, decoder_input_seq], verbose=0)\n",
    "    predicted_id = np.argmax(predictions[0, i - 1, :])\n",
    "\n",
    "    # 예측된 토큰이 END_TOKEN이면 요약 종료\n",
    "    if predicted_id == summary_tokenizer.word_index['<end>']:\n",
    "        break\n",
    "\n",
    "    # 예측된 토큰을 디코더 입력 시퀀스에 추가\n",
    "    decoder_input_seq[0, i] = predicted_id\n",
    "\n",
    "    # 예측된 단어를 요약에 추가\n",
    "    if predicted_id != 0:\n",
    "        predicted_summary += summary_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "print(\"Predicted Summary:\", predicted_summary.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1958232e420451aa331e84db4121e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\envym\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\envym\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80c4942a8e945ecba78bddce778e40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b23c74eb234adb8f5f74b832abb90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826fb2868e4e416cb576636587f0a0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71cde205e9c48aa904a14b92c137466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5c79c7973f4713b01efe299892e5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Summary: the Indian stock market saw a significant drop today amid growing concerns over the global economic downturn. the new iphone 15 features an upgraded camera system, faster processor, and a new design with titanium edges.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# T5 모델과 토크나이저 로드\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 테스트할 텍스트\n",
    "example_text = \"\"\"\n",
    "The Indian stock market witnessed a significant drop today amid growing concerns over the global economic downturn.\n",
    "Apple has announced the release of its new iPhone 15, which features an upgraded camera system, faster processor, \n",
    "and a new design with titanium edges. The phone will be available for pre-order starting next week, \n",
    "with shipping expected by the end of the month.\n",
    "\"\"\"\n",
    "\n",
    "input_text = \"summarize: \" + example_text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# 요약 생성\n",
    "summary_ids = model.generate(input_ids, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Predicted Summary:\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
